{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import ftfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a new CSV file, incorporating all CSVs in 'event_data' directory\n",
    "\n",
    "desired_cols = ['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId']\n",
    "header = None\n",
    "\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "# for every filepath in the file path list \n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as output_file:\n",
    "    writer = csv.writer(output_file, dialect='myDialect')\n",
    "    writer.writerow(desired_cols)\n",
    "    \n",
    "    for path in file_path_list:\n",
    "        # reading input csv file \n",
    "        with open(path, 'r', encoding = 'utf8', newline='') as input_file: \n",
    "            # creating a csv reader object \n",
    "            csvreader = csv.reader(input_file)\n",
    "            input_header = next(csvreader)\n",
    "\n",
    "            #Checking columns of all files ordered the same:\n",
    "            if header != None:\n",
    "                if header != input_header:\n",
    "                    raise Exception(f\"File {path} has differently-ordered columns\")\n",
    "            else:\n",
    "                header = input_header\n",
    "                #Object for ensuring we order columns consistently:\n",
    "                h_indices = {key: val for val, key in enumerate(header)}\n",
    "\n",
    "            # extracting each data row one by one andlist append it        \n",
    "            for line in csvreader:\n",
    "                if line[0] == '':\n",
    "                    continue\n",
    "                #Fixing corrupted characters\n",
    "                line = [ftfy.fix_text(item) for item in line]\n",
    "                #Writing columns in order specified by desired_cols\n",
    "                writer.writerow([line[h_indices[key]] for key in desired_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Creating Cassandra tables & inserting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating & connecting to a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = ['127.0.0.1']\n",
    "port = 9042 #Port 9042 used because I'm connecting to Docker-hosted Cassandra instance which has this port exposed\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(contact_points = contacts, port = port)\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute('''\n",
    "    CREATE KEYSPACE IF NOT EXISTS music_sparkify_cassandra\n",
    "    WITH REPLICATION =\n",
    "    {'class':'SimpleStrategy','replication_factor':'1'}\n",
    "    ''')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('music_sparkify_cassandra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def data_insert(table,attributes_dict):\n",
    "    '''reads in file below and inserts into user-given Cassandra table with user-specified attributes'''\n",
    "    file = 'event_datafile_new.csv'\n",
    "\n",
    "    query = make_insert_query_string(table,attributes_dict)\n",
    "\n",
    "    with open(file, encoding = 'utf8') as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        columns = next(csvreader) # record & skip col names\n",
    "        for line in csvreader:\n",
    "            values = get_insert_values(columns, attributes_dict,line)\n",
    "            session.execute(query, tuple(values))\n",
    "\n",
    "def make_insert_query_string(table, attributes):\n",
    "    '''Creates basic insert query string for Cassandra given table name and list of values'''\n",
    "    attributes_str = \", \".join(attributes)\n",
    "    values_str = \", \".join([\"%s\"]*len(attributes))\n",
    "    query = f\"INSERT INTO {table} ({attributes_str}) VALUES ({values_str})\"\n",
    "    return query\n",
    "\n",
    "def get_insert_values(columns, attribute_dict, data):\n",
    "    '''\n",
    "    Casts data values as type defined by 'attribute_dict'.\n",
    "    Uses 'columns' to ensure that the correct index of 'data' is being used.\n",
    "    Requires that all values in attribute_dict.keys() match an element in 'columns'\n",
    "    '''\n",
    "    return [func(data[columns.index(attr)]) for attr,func in attribute_dict.items()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query #1\n",
    "Give me the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS songs_by_session\n",
    "    (sessionId int,\n",
    "    itemInSession int,\n",
    "    artist text,\n",
    "    song text,\n",
    "    length float,\n",
    "    PRIMARY KEY (sessionId, itemInSession))\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO songs_by_session (sessionId, itemInSession, artist, song, length) VALUES (%s, %s, %s, %s, %s)\n"
     ]
    }
   ],
   "source": [
    "#Inserting data to newly-created table\n",
    "attributes_dict = {\n",
    "    'sessionId':int,\n",
    "    'itemInSession':int,\n",
    "    'artist':str,\n",
    "    'song':str,\n",
    "    'length':float\n",
    "}\n",
    "table = 'songs_by_session'\n",
    "\n",
    "data_insert(table,attributes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Verifying data insertion through SELECT statement\n",
    "result = session.execute(\n",
    "    '''SELECT artist,song,length FROM songs_by_session WHERE sessionId = 338 AND itemInSession = 4'''\n",
    ")\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query #2\n",
    "Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS songsUser_by_sessionUser\n",
    "    (userId int,\n",
    "    sessionId int,\n",
    "    itemInSession int,\n",
    "    artist text,\n",
    "    song text,\n",
    "    firstName text,\n",
    "    lastName text,\n",
    "    PRIMARY KEY (userId, sessionId, itemInSession))\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO songsUser_by_sessionUser (sessionId, userId, itemInSession, artist, song, firstName, lastName) VALUES (%s, %s, %s, %s, %s, %s, %s)\n"
     ]
    }
   ],
   "source": [
    "#Inserting data to newly-created table\n",
    "attributes_dict = {\n",
    "    'userId':int,\n",
    "    'sessionId':int,\n",
    "    'itemInSession':int,\n",
    "    'artist':str,\n",
    "    'song':str,\n",
    "    'firstName':str,\n",
    "    'lastName':str\n",
    "}\n",
    "table = 'songsUser_by_sessionUser'\n",
    "\n",
    "data_insert(table,attributes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying data insertion through SELECT statement\n",
    "result = session.execute(\n",
    "    '''SELECT artist,song,firstName,lastName FROM songsUser_by_sessionUser WHERE userId = 10 AND sessionId = 182 ORDER BY itemInSession'''\n",
    ")\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3\n",
    "Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS users_by_song\n",
    "    (\n",
    "    artist text,\n",
    "    song text,\n",
    "    userId int,\n",
    "    firstName text,\n",
    "    lastName text,\n",
    "    PRIMARY KEY (artist, song, userId))\n",
    "    '''\n",
    ")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserting data to newly-created table\n",
    "attributes_dict = {\n",
    "    'artist':str,\n",
    "    'song':str,\n",
    "    'userId':int,\n",
    "    'firstName':str,\n",
    "    'lastName':str\n",
    "}\n",
    "\n",
    "table = 'users_by_song'\n",
    "\n",
    "data_insert(table,attributes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying data insertion through SELECT statement\n",
    "result = session.execute(\n",
    "    \"SELECT firstName,lastName FROM users_by_song WHERE artist = 'The Black Keys' AND song = 'All Hands Against His Own'\"\n",
    ")\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"DROP TABLE songs_by_session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"DROP TABLE songsUser_by_sessionUser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"DROP TABLE users_by_song\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
