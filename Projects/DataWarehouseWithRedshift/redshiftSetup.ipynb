{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift Setup with Python SDK (boto3)\n",
    "This notebook will show how to set up some AWS resources using the Python SDK for AWS, boto3.\n",
    "\n",
    "Boto3 Documentation: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Package Import\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Loading Config files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS Credentials\n",
    "aws_path = \"/home/rambino/.aws/credentials\"\n",
    "aws_cred = configparser.ConfigParser()\n",
    "aws_cred.read(aws_path)\n",
    "\n",
    "#Redshift Credentials\n",
    "redshift_path = \"/home/rambino/dev/DataEngineering_Udacity/04_AWS_DataWarehousing/redshift_credentials.cfg\"\n",
    "redshift_cred = configparser.ConfigParser()\n",
    "redshift_cred.read(redshift_path)\n",
    "\n",
    "#ETL Config\n",
    "cfg_path = \"/home/rambino/dev/DataEngineering_Udacity/Projects/DataWarehouseWithRedshift/dwh.cfg\"\n",
    "cfg = configparser.ConfigParser()\n",
    "cfg.read(cfg_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Creating IAM role for Redshift\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3',\n",
    "    region_name             = \"us-west-2\",\n",
    "    aws_access_key_id       = aws_cred['udacity_course']['aws_access_key_id'],\n",
    "    aws_secret_access_key   = aws_cred['udacity_course']['aws_secret_access_key']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(\"udacity-dend\",\"log_json_path.json\",\"redshift_project_json_format.json\")\n",
    "#s3://udacity-dend/log_json_path.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client('iam',\n",
    "    region_name             = \"us-west-2\",\n",
    "    aws_access_key_id       = aws_cred['udacity_course']['aws_access_key_id'],\n",
    "    aws_secret_access_key   = aws_cred['udacity_course']['aws_secret_access_key']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create IAM role:\n",
    "\n",
    "#This policy is something about allowing Redshift to impersonate a user, but I don't really understand it.\n",
    "#Look more into what \"sts:AssumeRole\" really means.\n",
    "\n",
    "import json\n",
    "\n",
    "dwhRole = iam.create_role(\n",
    "    Path = \"/\",\n",
    "    RoleName =  \"RedShift_Impersonation\",\n",
    "    Description = \"Allows redshift to access S3\",\n",
    "    AssumeRolePolicyDocument=json.dumps(\n",
    "        {\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "                {\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": 'sts:AssumeRole',\n",
    "                    \"Principal\":{\"Service\": \"redshift.amazonaws.com\"}\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "dwhRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = iam.get_role(RoleName = \"Redshift_Impersonation\")\n",
    "role_arn = role['Role']['Arn']\n",
    "role_arn\n",
    "\n",
    "#Loading IAM ARN into config file\n",
    "cfg['IAM_ROLE']['ARN'] = role_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attaching IAM policy to the role (which actually gives permissions):\n",
    "\n",
    "attach_response = iam.attach_role_policy(\n",
    "    RoleName = \"RedShift_Impersonation\",\n",
    "    PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    ")\n",
    "\n",
    "attach_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Apply VPC Security Group rules to Redshift\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining PORT for Redshift + VPC security group\n",
    "redshift_port = 5439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.client('ec2',\n",
    "    region_name             = \"us-west-2\",\n",
    "    aws_access_key_id       = aws_cred['udacity_course']['aws_access_key_id'],\n",
    "    aws_secret_access_key   = aws_cred['udacity_course']['aws_secret_access_key']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ec2.create_security_group(\n",
    "    Description = \"Security Group for allowing all access to Redshift cluster\",\n",
    "    GroupName = \"Redshift_secGroup\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_groups = ec2.describe_security_groups(\n",
    "    GroupNames = [\n",
    "        'Redshift_secGroup'\n",
    "    ]\n",
    ")\n",
    "\n",
    "sec_groups\n",
    "redshift_sg_id = sec_groups['SecurityGroups'][0]['GroupId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpc = ec2.authorize_security_group_ingress(\n",
    "    CidrIp = '0.0.0.0/0', #Allowing permission to access from any IP\n",
    "    FromPort = redshift_port, #Default port for Redshift\n",
    "    ToPort = redshift_port,\n",
    "    IpProtocol = 'TCP',\n",
    "    GroupId = redshift_sg_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Creating Redshift cluster\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = boto3.client('redshift',\n",
    "    region_name             = \"us-west-2\",\n",
    "    aws_access_key_id       = aws_cred['udacity_course']['aws_access_key_id'],\n",
    "    aws_secret_access_key   = aws_cred['udacity_course']['aws_secret_access_key']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Documentation: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html#Redshift.Client.create_cluster\n",
    "redshift_response = redshift.create_cluster(\n",
    "    ClusterType = \"multi-node\",\n",
    "    NodeType = 'dc2.large',\n",
    "    NumberOfNodes = 4,\n",
    "    DBName = \"my_redshift_db\",\n",
    "    ClusterIdentifier = 'redshift-cluster-2',\n",
    "    MasterUsername = redshift_cred['redshift_credentials']['un'],\n",
    "    MasterUserPassword = redshift_cred['redshift_credentials']['pw'],\n",
    "    IamRoles = [role_arn],\n",
    "    PubliclyAccessible = True,\n",
    "    VpcSecurityGroupIds = [\n",
    "        redshift_sg_id\n",
    "    ],\n",
    "    Port = redshift_port\n",
    ")\n",
    "\n",
    "'''\n",
    "WARNING! After running this code, you WILL create a Redshift cluster. Be sure to delete it to not incur costs!!\n",
    "'''\n",
    "\n",
    "redshift_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "#Cluster takes time to create. This loop iterates until redshift is finished and returns details:\n",
    "for i in range(20):\n",
    "    clusters = redshift.describe_clusters()\n",
    "    if(clusters['Clusters'] == []):\n",
    "        print(\"cluster still forming...\")\n",
    "        sleep(5)\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            cfg['CLUSTER']['DB_HOST'] = clusters['Clusters'][0]['Endpoint']['Address']\n",
    "            cfg['CLUSTER']['DB_PORT'] = str(clusters['Clusters'][0]['Endpoint']['Port'])\n",
    "            cfg['CLUSTER']['DB_NAME'] = clusters['Clusters'][0]['DBName']\n",
    "            cluster_id = clusters['Clusters'][0]['ClusterIdentifier']\n",
    "\n",
    "            cfg['CLUSTER']['DB_USER'] = redshift_cred['redshift_credentials']['UN']\n",
    "            cfg['CLUSTER']['DB_PASSWORD'] = redshift_cred['redshift_credentials']['PW']\n",
    "            print(\"---Variables Loaded Successfully---\")\n",
    "            print(clusters)\n",
    "            break\n",
    "        except:\n",
    "            print(\"Error in outputting cluster metrics, trying again...\")\n",
    "            sleep(10)\n",
    "\n",
    "    \n",
    "\n",
    "    #if(clusters['Clusters'] == []):\n",
    "    #   print(\"No clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Config file:\n",
    "with open(cfg_path,\"w\") as file:\n",
    "    cfg.write(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Attempt to connect to Redshift cluster:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = f'''\n",
    "    postgresql://{cfg['CLUSTER']['DB_USER']}:{cfg['CLUSTER']['DB_PASSWORD']}@{cfg['CLUSTER']['DB_HOST']}:{cfg['CLUSTER']['DB_PORT']}/{cfg['CLUSTER']['DB_NAME']}'''\n",
    "\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Troubleshooting issues with data transfer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT current_database();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query load errors:\n",
    "%sql select * from stl_load_errors ORDER BY starttime desc limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-checking that 'songplays' database only has events with a valid song, artist and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT COUNT(*)\n",
    "FROM songplays\n",
    "WHERE artist_id IS NULL OR artist_id = ''\n",
    "OR song_id IS NULL OR song_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-checking we only have unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT user_id, COUNT(user_id) count\n",
    "FROM users\n",
    "GROUP BY user_id\n",
    "ORDER BY count DESC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-checking we only have unique songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT song_id, COUNT(song_id) count\n",
    "FROM songs\n",
    "GROUP BY song_id\n",
    "ORDER BY count DESC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-checking we only have unique artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT artist_id, COUNT(artist_id) count\n",
    "FROM artists\n",
    "GROUP BY artist_id\n",
    "ORDER BY count DESC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where were users located during their Sparkify sessions on November 30, 2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT COUNT(*) AS freq, location\n",
    "FROM songplays\n",
    "JOIN time ON songplays.start_time = time.start_time\n",
    "WHERE time.year = 2018 \n",
    "AND time.month = 11  \n",
    "AND time.day = 30 \n",
    "GROUP BY songplays.location \n",
    "ORDER BY freq DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the most popular songs (i.e., most played) in Q4, 2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%sql\n",
    "\n",
    "SELECT COUNT(*) freq, songplays.song_id, songs.title \n",
    "FROM songplays JOIN time ON songplays.start_time = time.start_time \n",
    "LEFT JOIN songs on songplays.song_id = songs.song_id \n",
    "WHERE time.year = 2018\n",
    "AND time.month BETWEEN 10 AND 12\n",
    "GROUP BY songplays.song_id, songs.title \n",
    "ORDER BY freq DESC\n",
    "LIMIT 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE CLUSTER\n",
    "response = redshift.delete_cluster(\n",
    "    ClusterIdentifier = cluster_id,\n",
    "    SkipFinalClusterSnapshot=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
