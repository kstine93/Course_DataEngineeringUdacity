{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMR Setup with Python SDK (boto3)\n",
    "This notebook will show how to set up some AWS resources using the Python SDK for AWS, boto3.\n",
    "\n",
    "Boto3 Documentation: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Package Import\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Loading Credentials from file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rambino/.aws/credentials']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AWS Credentials\n",
    "aws_path = \"/home/rambino/.aws/credentials\"\n",
    "aws_cred = configparser.ConfigParser()\n",
    "aws_cred.read(aws_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Create SSH keypair for connecting to EC2 instances\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.client('ec2',\n",
    "    region_name             = \"us-east-1\",\n",
    "    aws_access_key_id       = aws_cred['default']['aws_access_key_id'],\n",
    "    aws_secret_access_key   = aws_cred['default']['aws_secret_access_key']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ec2.create_key_pair(\n",
    "    KeyName = 'spark_ec2_key',\n",
    "    DryRun=False,\n",
    "    KeyFormat='pem'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/rambino/.aws/spark_keypair.pem',\"w\") as file:\n",
    "    file.writelines(response['KeyMaterial'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Setting up VPC for the EMR cluster\n",
    "\n",
    "---\n",
    "\n",
    "If no VPC is specified for an EMR cluster, then the cluster is launched in the normal AWS cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating default VPC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (DefaultVpcAlreadyExists) when calling the CreateDefaultVpc operation: A Default VPC already exists for this account in this region.\n"
     ]
    }
   ],
   "source": [
    "!aws ec2 create-default-vpc --profile default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting **first** subnetId for this VPC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpc_output = ec2.describe_vpcs()\n",
    "\n",
    "#Getting first (and only) VPC:\n",
    "vpcId = vpc_output['Vpcs'][0]['VpcId']\n",
    "\n",
    "subnet_output = ec2.describe_subnets(\n",
    "    Filters=[\n",
    "        {\n",
    "            'Name':'vpc-id',\n",
    "            'Values':[vpcId]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "subnetId = subnet_output['Subnets'][0]['SubnetId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Creating EMR Cluster\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps needed to set up and connect to EMR:**\n",
    "1. set up cluster with correct specifications\n",
    "2. get 'master public DNS' for the cluster\n",
    "3. edit security group to allow my computer to connect via SSH (add inbound rule to allow SSH connection from my IP)\n",
    "   1. Note: Security group is distinct entity from cluster - why not just set this up beforehand?\n",
    "      1. Note: It IS possible to set up a security group beforehand - and to specify this security group for the master and slave nodes. For a more official setup, it's probably better to do this to ensure that the security group we set up for EMR is custom-defined (and not default).\n",
    "      2. UPDATE: Well, actually when you CREATE a cluster, security groups are created automatically for the cluster on the default VPC. I could go through the trouble to set up custom security groups *beforehand*, or I could just create the cluster and then change the security groups as needed once they are created. Since I can't think of a reason it would be better to create custom security groups beforehand rather than just edit the ones which are created for me, I will just edit the ones created for me in this code.\n",
    "4. Set up proxy to access \"persistent web UI for Spark\"?\n",
    "   1. This looks like it's for being able to view the Spark UI somehow, but the way they're setting up the proxy settings and filtering URLs seems really hacky (e.g., they're filtering urls matching \"http://10.*)\". I'm not sure I want to set this up until I know that it's much better than using AWS' built-in UI viewer.\n",
    "   2. Update: **It turns out that AWS also recommends using FoxyProxy (or other tools) to connect to Spark UIs on EMR**, so I will in fact do this now.\n",
    "      1. [read more here](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-web-interfaces.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emr = boto3.client('emr',\n",
    "    region_name             = \"us-east-1\",\n",
    "    aws_access_key_id       = aws_cred['default']['aws_access_key_id'],\n",
    "    aws_secret_access_key   = aws_cred['default']['aws_secret_access_key']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JobFlowId': 'j-1G9MDNZM8AK80',\n",
       " 'ClusterArn': 'arn:aws:elasticmapreduce:us-east-1:549653882425:cluster/j-1G9MDNZM8AK80',\n",
       " 'ResponseMetadata': {'RequestId': 'fd542ec6-5c0d-4248-b1b0-f0c9fdb7aaeb',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'fd542ec6-5c0d-4248-b1b0-f0c9fdb7aaeb',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '118',\n",
       "   'date': 'Wed, 14 Sep 2022 18:07:14 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With boto3\n",
    "emr.run_job_flow(\n",
    "            Name='spark-cluster',\n",
    "            LogUri='s3://emrlogs/',\n",
    "            ReleaseLabel='emr-5.28.0',\n",
    "            Instances={\n",
    "                'MasterInstanceType': 'm5.xlarge',\n",
    "                'SlaveInstanceType': 'm5.xlarge',\n",
    "                'InstanceCount': 4,\n",
    "                'Ec2KeyName':'spark_ec2_key',\n",
    "                'KeepJobFlowAliveWhenNoSteps': True\n",
    "                #'EmrManagedMasterSecurityGroup': security_groups['manager'].id,\n",
    "                #'EmrManagedSlaveSecurityGroup': security_groups['worker'].id,\n",
    "            },\n",
    "            Applications=[\n",
    "                {\n",
    "                    \"Name\":\"Spark\"\n",
    "                },\n",
    "                {\n",
    "                    \"Name\":\"Zeppelin\"\n",
    "                }\n",
    "            ],\n",
    "            JobFlowRole='EMR_EC2_DefaultRole',\n",
    "            ServiceRole='EMR_DefaultRole',\n",
    "            VisibleToAllUsers=True\n",
    "        )\n",
    "\n",
    "#NOTE: Under the 'Applications' specification of the EMR cluster above, you can also load in applications like\n",
    "# Spark, TensorFlow, Presto, and Hadoop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ClusterId\": \"j-YR7XBL53LHQW\",\n",
      "    \"ClusterArn\": \"arn:aws:elasticmapreduce:us-east-1:549653882425:cluster/j-YR7XBL53LHQW\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#with AWS CLI:\n",
    "\n",
    "!aws emr create-cluster --name test-cluster \\\n",
    "    --use-default-roles \\\n",
    "    --release-label emr-5.28.0 \\\n",
    "    --instance-count 4 \\\n",
    "    --applications Name=Spark Name=Zeppelin \\\n",
    "    --ec2-attributes KeyName='spark_ec2_key',SubnetId='subnet-0b6cc9cfba9463659'\\\n",
    "    --instance-type m5.xlarge \\\n",
    "    --log-uri s3://emrlogs/ \\\n",
    "    --visible-to-all-users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Configuring Cluster\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Clusters': [{'Id': 'j-1G9MDNZM8AK80', 'Name': 'spark-cluster', 'Status': {'State': 'STARTING', 'StateChangeReason': {}, 'Timeline': {'CreationDateTime': datetime.datetime(2022, 9, 14, 20, 7, 15, 117000, tzinfo=tzlocal())}}, 'NormalizedInstanceHours': 0, 'ClusterArn': 'arn:aws:elasticmapreduce:us-east-1:549653882425:cluster/j-1G9MDNZM8AK80'}], 'ResponseMetadata': {'RequestId': '030d99e7-4228-410a-8fd0-f754cf43d04e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '030d99e7-4228-410a-8fd0-f754cf43d04e', 'content-type': 'application/x-amz-json-1.1', 'content-length': '279', 'date': 'Wed, 14 Sep 2022 18:08:42 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "cluster_list = emr.list_clusters(\n",
    "    ClusterStates=['STARTING','RUNNING']\n",
    ")\n",
    "print(cluster_list)\n",
    "cluster_id = cluster_list['Clusters'][0]['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cluster = emr.describe_cluster(\n",
    "    ClusterId = cluster_id\n",
    ")\n",
    "new_cluster\n",
    "secGroup_master = new_cluster['Cluster']['Ec2InstanceAttributes']['EmrManagedMasterSecurityGroup']\n",
    "cluster_dns = new_cluster['Cluster']['MasterPublicDnsName']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Cluster Security Groups to only accept SSH ingress from my IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting my public IP address from config.me website (IP is last element of returned array)\n",
    "myIP = !curl ifconfig.me\n",
    "myIP = myIP[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying internal port (arbitrary?)\n",
    "myPort = '32'\n",
    "myCidrIp = myIP + \"/\" + myPort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 88.117.176.62/32, TCP, from port: 22, to port: 22, ALLOW\" already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response \u001b[39m=\u001b[39m ec2\u001b[39m.\u001b[39;49mauthorize_security_group_ingress(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     GroupId\u001b[39m=\u001b[39;49msecGroup_master,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     IpPermissions\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         {\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mFromPort\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m22\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mIpProtocol\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mtcp\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mIpRanges\u001b[39;49m\u001b[39m'\u001b[39;49m: [\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                 {\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                     \u001b[39m'\u001b[39;49m\u001b[39mCidrIp\u001b[39;49m\u001b[39m'\u001b[39;49m: myCidrIp,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                     \u001b[39m'\u001b[39;49m\u001b[39mDescription\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mSSH access to Spark EMR on AWS from Kevins Computer\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                 },\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mToPort\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m22\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         },\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rambino/dev/DataEngineering_Udacity/05_Spark_DataLakes/AWS_EMR_Practice/EMR_boto3Setup.ipynb#X34sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botocore/client.py:508\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    505\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botocore/client.py:915\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    913\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    914\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 88.117.176.62/32, TCP, from port: 22, to port: 22, ALLOW\" already exists"
     ]
    }
   ],
   "source": [
    "response = ec2.authorize_security_group_ingress(\n",
    "    GroupId=secGroup_master,\n",
    "    IpPermissions=[\n",
    "        {\n",
    "            'FromPort': 22,\n",
    "            'IpProtocol': 'tcp',\n",
    "            'IpRanges': [\n",
    "                {\n",
    "                    'CidrIp': myCidrIp,\n",
    "                    'Description': 'SSH access to Spark EMR on AWS from Kevins Computer',\n",
    "                },\n",
    "            ],\n",
    "            'ToPort': 22,\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Interacting with Cluster\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File path where cluster login information is kept on my machine:\n",
    "pem_path = '/home/rambino/.aws/spark_keypair.pem'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Cluster via SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh hadoop@ec2-34-236-148-89.compute-1.amazonaws.com -i /home/rambino/.aws/spark_keypair.pem\n"
     ]
    }
   ],
   "source": [
    "#Command to use in terminal (interactive):\n",
    "print(f\"ssh hadoop@{cluster_dns} -i {pem_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Proxy connection to allow interaction with Spark UI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up FoxyProxy to allow connection to Spark UI from localhost\n",
    "[AWS Documentation on Port forwarding for EMR connections](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-ssh-tunnel.html)\n",
    "\n",
    "\n",
    "I needed to install the browser extension FoxyProxy to allow my browser to interface with the EMR cluster. Once I installed it, I then needed to set up a new proxy with these settings:\n",
    "- IP address: `localhost`\n",
    "- Port: `8157` (only needed to match dynamic port forwarding below)\n",
    "\n",
    "Then, in the 'pattern matching' part, I needed to specify which URLs should be forwarded in this way. This was already specified by Udacity. The json file accompanying this notebook named 'foxyproxy...' shows these patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scp -i /home/rambino/.aws/spark_keypair.pem /home/rambino/.aws/spark_keypair.pem hadoop@ec2-34-236-148-89.compute-1.amazonaws.com:/home/hadoop/\n"
     ]
    }
   ],
   "source": [
    "#Copying credentials file to the master node (not sure why yet)\n",
    "print(f\"scp -i {pem_path} {pem_path} hadoop@{cluster_dns}:/home/hadoop/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh -v -i /home/rambino/.aws/spark_keypair.pem -N -D 127.0.0.1:8157 hadoop@ec2-34-236-148-89.compute-1.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "#This sets up port forwarding (somehow) so that data from our local machine on port 8157 is forwarded to the master node (allowing interactivity)\n",
    "#NOTE: Terminal remains open when this request succeeds - and needs to remain running while accessing Spark UI\n",
    "\n",
    "#Note: Getting this SSH connection to work has been unpredictable at times. Often get 'connection refused' errors, but then it\n",
    "#suddenly works. Should ideally figure out what's going on there...\n",
    "\n",
    "print(f\"ssh -v -i {pem_path} -N -D 127.0.0.1:8157 hadoop@{cluster_dns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing Spark UI:\n",
    "- Base URL:           http://ec2-54-87-42-167.compute-1.amazonaws.com\n",
    "\n",
    "- Spark History:      http://ec2-54-87-42-167.compute-1.amazonaws.com:18080/\n",
    "- YARN Node Manager:  http://ec2-54-87-42-167.compute-1.amazonaws.com:8042/\n",
    "\n",
    "\n",
    "[See more ports here](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-web-interfaces.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Deleting EMR Cluster (Teardown)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0712bc2f-b997-4dac-8f6a-896c46c58bda',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0712bc2f-b997-4dac-8f6a-896c46c58bda',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Wed, 14 Sep 2022 19:52:32 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emr.terminate_job_flows(\n",
    "    JobFlowIds=[\n",
    "        cluster_id\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
